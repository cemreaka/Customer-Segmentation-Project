{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer Segmentation - Group Project\n",
    "Customer Segmentation\n",
    "Problem Statement:  XYZ bank wants to roll out Christmas offers to their customers. But Bank does not want to roll out same offer to all customers  instead they want to roll out personalized offer to particular set of customers. If they manually start understanding the category of customer then this will be not efficient and also they will not be able to uncover the hidden pattern in the data ( pattern which group certain kind of customer in one category). Bank approached ABC analytics company to solve their problem. Bank also shared information with ABC analytics that they don't want more than 5 group as this will be inefficient for their campaign.\n",
    "\n",
    "ML Problem: ABC analytics proposed customer segmentation approach to Bank.\n",
    "\n",
    "ABC analytics assigned this talk to their analytics team and instructed their team to come up with the approach and feature which group similar behavior customer in one category and others in different category.\n",
    "\n",
    "Note: Please read problem statement carefully and propose the approach which should be as per the customer requirement.\n",
    "\n",
    "Task:\n",
    "\n",
    "1. Business Understanding\n",
    "\n",
    "2. Data Understanding\n",
    "\n",
    "3. EDA\n",
    "\n",
    "4. Feature Engineering\n",
    "\n",
    "4. Model Building\n",
    "\n",
    "5. Model Evaluation\n",
    "\n",
    "6. Presentation (Recommendation slide is must)\n",
    "\n",
    "7. Document the challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**Column Name**|Description|\n",
    "| --- | --- |\n",
    "|**fecha_dato**|The table is partitioned for this column|\n",
    "|**cust_code**|\tCustomer code|\n",
    "|**emp_index**|Employee index: A active, B ex employed, F filial, N not employee, P pasive|\n",
    "|**cust_residence**|Customer's Country residence|\n",
    "|**'cust_gender**|Customer's sex|\n",
    "|**age**|Age|\n",
    "|**first_holder_date**|The date in which the customer became as the first holder of a contract in the bank|\n",
    "|**new_cust_index**|New customer Index. 1 if the customer registered in the last 6 months|\n",
    "|**cust_seniority**|Customer seniority (in months)|\n",
    "|**indrel**|1 (First/Primary), 99 (Primary customer during the month but not at the end of the month)|\n",
    "|**last_date_primary_cust**|Last date as primary customer (if he isn't at the end of the month)|\n",
    "|**cust_type**|Customer type at the beginning of the month: 1 (First/Primary customer), 2 (co-owner), P (Potential), 3 (former primary), 4(former co-owner)|\n",
    "|**cust_rel_time**|Customer relation type at the beginning of the month: A (active), I (inactive), P (former customer), R (Potential)|\n",
    "|**cust_res_index**|Residence index (S (Yes) or N (No) if the residence country is the same than the bank country)|\n",
    "|**'is_foreign**|Foreigner index (S (Yes) or N (No) if the customer's birth country is different than the bank country)|\n",
    "|**cust_spouse_index**|Spouse index. 1 if the customer is spouse of an employee|\n",
    "|**channel_to_join**|channel used by the customer to join|\n",
    "|**deceased_index**|Deceased index. N/S|\n",
    "|**addres_type**|Addres type. 1, primary address|\n",
    "|**cod_prov**|Province code (customer's address)|\n",
    "|**name_province**|Province name|\n",
    "|**activity_index**|Activity index (1, active customer; 0, inactive customer)|\n",
    "|**household_income**|Gross income of the household|\n",
    "|**saving_acc**|Saving Account|\n",
    "|**guarantees**|Guarantees|\n",
    "|**current_acc**|Current Accounts|\n",
    "|**derivada_acc**|Derivada Account|\n",
    "|**payroll_acc**|Payroll Account|\n",
    "|**junior_acc**|Junior Account|\n",
    "|**mass_particular_acc**|Más particular Account|\n",
    "|**particular_acc**|particular Account|\n",
    "|**particular_plus_acc**|particular Plus Account|\n",
    "|**short_term_deposit**|Short-term deposits|\n",
    "|**long_term_deposit**|Medium-term deposits|\n",
    "|**ind_dela_fin_ult1**|Long-term deposits|\n",
    "|**e_account**|e-account|\n",
    "|**funds**|Funds|\n",
    "|**mortgage**|Mortgage|\n",
    "|**pensions1**|Pensions|\n",
    "|**loans**|Loans|\n",
    "|**taxes**|Taxes|\n",
    "|**credit_card**|Credit Card|\n",
    "|**securities**|Securities|\n",
    "|**home_account**|Home Account|\n",
    "|**payroll**|Payroll|\n",
    "|**pensions2**|Pensions|\n",
    "|**direct_debit**|Direct Debit|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "template = 'simple_white'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1</th>\n",
       "      <th>ind_plan_fin_ult1</th>\n",
       "      <th>ind_pres_fin_ult1</th>\n",
       "      <th>ind_reca_fin_ult1</th>\n",
       "      <th>ind_tjcr_fin_ult1</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_nomina_ult1</th>\n",
       "      <th>ind_nom_pens_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1375586</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>35</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050611</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050612</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050613</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050614</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>999995</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>1183296</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>27</td>\n",
       "      <td>2013-09-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>999996</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>1183295</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>56</td>\n",
       "      <td>2013-09-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>999997</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>1183294</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>39</td>\n",
       "      <td>2013-09-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>999998</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>1183293</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>36</td>\n",
       "      <td>2013-09-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>999999</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>1183289</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>38</td>\n",
       "      <td>2013-09-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  fecha_dato  ncodpers ind_empleado pais_residencia sexo  \\\n",
       "0                0  2015-01-28   1375586            N              ES    H   \n",
       "1                1  2015-01-28   1050611            N              ES    V   \n",
       "2                2  2015-01-28   1050612            N              ES    V   \n",
       "3                3  2015-01-28   1050613            N              ES    H   \n",
       "4                4  2015-01-28   1050614            N              ES    V   \n",
       "...            ...         ...       ...          ...             ...  ...   \n",
       "999995      999995  2015-02-28   1183296            N              ES    H   \n",
       "999996      999996  2015-02-28   1183295            N              ES    H   \n",
       "999997      999997  2015-02-28   1183294            N              ES    V   \n",
       "999998      999998  2015-02-28   1183293            N              ES    V   \n",
       "999999      999999  2015-02-28   1183289            N              ES    H   \n",
       "\n",
       "        age  fecha_alta  ind_nuevo antiguedad  ...  ind_hip_fin_ult1  \\\n",
       "0        35  2015-01-12        0.0          6  ...                 0   \n",
       "1        23  2012-08-10        0.0         35  ...                 0   \n",
       "2        23  2012-08-10        0.0         35  ...                 0   \n",
       "3        22  2012-08-10        0.0         35  ...                 0   \n",
       "4        23  2012-08-10        0.0         35  ...                 0   \n",
       "...     ...         ...        ...        ...  ...               ...   \n",
       "999995   27  2013-09-25        0.0         22  ...                 0   \n",
       "999996   56  2013-09-25        0.0         22  ...                 0   \n",
       "999997   39  2013-09-25        0.0         22  ...                 0   \n",
       "999998   36  2013-09-25        0.0         22  ...                 0   \n",
       "999999   38  2013-09-25        0.0         22  ...                 0   \n",
       "\n",
       "       ind_plan_fin_ult1  ind_pres_fin_ult1 ind_reca_fin_ult1  \\\n",
       "0                      0                  0                 0   \n",
       "1                      0                  0                 0   \n",
       "2                      0                  0                 0   \n",
       "3                      0                  0                 0   \n",
       "4                      0                  0                 0   \n",
       "...                  ...                ...               ...   \n",
       "999995                 0                  0                 0   \n",
       "999996                 0                  0                 0   \n",
       "999997                 0                  0                 0   \n",
       "999998                 0                  0                 0   \n",
       "999999                 0                  0                 0   \n",
       "\n",
       "       ind_tjcr_fin_ult1 ind_valo_fin_ult1 ind_viv_fin_ult1 ind_nomina_ult1  \\\n",
       "0                      0                 0                0             0.0   \n",
       "1                      0                 0                0             0.0   \n",
       "2                      0                 0                0             0.0   \n",
       "3                      0                 0                0             0.0   \n",
       "4                      0                 0                0             0.0   \n",
       "...                  ...               ...              ...             ...   \n",
       "999995                 0                 0                0             0.0   \n",
       "999996                 0                 0                0             0.0   \n",
       "999997                 0                 0                0             0.0   \n",
       "999998                 0                 0                0             0.0   \n",
       "999999                 0                 0                0             0.0   \n",
       "\n",
       "       ind_nom_pens_ult1  ind_recibo_ult1  \n",
       "0                    0.0                0  \n",
       "1                    0.0                0  \n",
       "2                    0.0                0  \n",
       "3                    0.0                0  \n",
       "4                    0.0                0  \n",
       "...                  ...              ...  \n",
       "999995               0.0                1  \n",
       "999996               0.0                0  \n",
       "999997               0.0                1  \n",
       "999998               0.0                1  \n",
       "999999               0.0                1  \n",
       "\n",
       "[1000000 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/joean/Desktop/Data Science/Personal Projects/cust_seg.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 48 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1000000 non-null  int64  \n",
      " 1   fecha_dato             1000000 non-null  object \n",
      " 2   ncodpers               1000000 non-null  int64  \n",
      " 3   ind_empleado           989218 non-null   object \n",
      " 4   pais_residencia        989218 non-null   object \n",
      " 5   sexo                   989214 non-null   object \n",
      " 6   age                    1000000 non-null  object \n",
      " 7   fecha_alta             989218 non-null   object \n",
      " 8   ind_nuevo              989218 non-null   float64\n",
      " 9   antiguedad             1000000 non-null  object \n",
      " 10  indrel                 989218 non-null   float64\n",
      " 11  ult_fec_cli_1t         1101 non-null     object \n",
      " 12  indrel_1mes            989218 non-null   float64\n",
      " 13  tiprel_1mes            989218 non-null   object \n",
      " 14  indresi                989218 non-null   object \n",
      " 15  indext                 989218 non-null   object \n",
      " 16  conyuemp               178 non-null      object \n",
      " 17  canal_entrada          989139 non-null   object \n",
      " 18  indfall                989218 non-null   object \n",
      " 19  tipodom                989218 non-null   float64\n",
      " 20  cod_prov               982266 non-null   float64\n",
      " 21  nomprov                982266 non-null   object \n",
      " 22  ind_actividad_cliente  989218 non-null   float64\n",
      " 23  renta                  824817 non-null   float64\n",
      " 24  ind_ahor_fin_ult1      1000000 non-null  int64  \n",
      " 25  ind_aval_fin_ult1      1000000 non-null  int64  \n",
      " 26  ind_cco_fin_ult1       1000000 non-null  int64  \n",
      " 27  ind_cder_fin_ult1      1000000 non-null  int64  \n",
      " 28  ind_cno_fin_ult1       1000000 non-null  int64  \n",
      " 29  ind_ctju_fin_ult1      1000000 non-null  int64  \n",
      " 30  ind_ctma_fin_ult1      1000000 non-null  int64  \n",
      " 31  ind_ctop_fin_ult1      1000000 non-null  int64  \n",
      " 32  ind_ctpp_fin_ult1      1000000 non-null  int64  \n",
      " 33  ind_deco_fin_ult1      1000000 non-null  int64  \n",
      " 34  ind_deme_fin_ult1      1000000 non-null  int64  \n",
      " 35  ind_dela_fin_ult1      1000000 non-null  int64  \n",
      " 36  ind_ecue_fin_ult1      1000000 non-null  int64  \n",
      " 37  ind_fond_fin_ult1      1000000 non-null  int64  \n",
      " 38  ind_hip_fin_ult1       1000000 non-null  int64  \n",
      " 39  ind_plan_fin_ult1      1000000 non-null  int64  \n",
      " 40  ind_pres_fin_ult1      1000000 non-null  int64  \n",
      " 41  ind_reca_fin_ult1      1000000 non-null  int64  \n",
      " 42  ind_tjcr_fin_ult1      1000000 non-null  int64  \n",
      " 43  ind_valo_fin_ult1      1000000 non-null  int64  \n",
      " 44  ind_viv_fin_ult1       1000000 non-null  int64  \n",
      " 45  ind_nomina_ult1        994598 non-null   float64\n",
      " 46  ind_nom_pens_ult1      994598 non-null   float64\n",
      " 47  ind_recibo_ult1        1000000 non-null  int64  \n",
      "dtypes: float64(9), int64(24), object(15)\n",
      "memory usage: 366.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'fecha_dato', 'ncodpers', 'ind_empleado',\n",
       "       'pais_residencia', 'sexo', 'age', 'fecha_alta', 'ind_nuevo',\n",
       "       'antiguedad', 'indrel', 'ult_fec_cli_1t', 'indrel_1mes', 'tiprel_1mes',\n",
       "       'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom',\n",
       "       'cod_prov', 'nomprov', 'ind_actividad_cliente', 'renta',\n",
       "       'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
       "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
       "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
       "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
       "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
       "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
       "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
       "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\n",
    "    'fecha_dato':'date', \n",
    "    'ncodpers':'cust_code', \n",
    "    'ind_empleado':'emp_index',\n",
    "    'pais_residencia':'cust_residence', \n",
    "    'indext':'is_foreign', \n",
    "    'sexo':'cust_gender', \n",
    "    'fecha_alta':'first_holder_date',\n",
    "    'ind_nuevo':'new_cust_index', \n",
    "    'antiguedad':'cust_seniority', \n",
    "    'ult_fec_cli_1t':'last_date_primary_cust', \n",
    "    'indrel_1mes':'cust_type', \n",
    "    'tiprel_1mes':'cust_rel_time', \n",
    "    'indresi':'cust_res_index',\n",
    "    'conyuemp':'cust_spouse_index',\n",
    "    'canal_entrada':'channel_to_join', \n",
    "    'nomprov':'name_province',\n",
    "    'ind_actividad_cliente':'activity_index' ,\n",
    "    'renta':'household_income',\n",
    "    'tipodom':'addres_type',\n",
    "    'indfall':'deceased_index',\n",
    "    'ind_ahor_fin_ult1':'saving_acc', \n",
    "    'ind_aval_fin_ult1': 'guarantees', \n",
    "    'ind_cder_fin_ult1':'derivada_acc', \n",
    "    'ind_cno_fin_ult1':'payroll_acc',\n",
    "    'ind_ctju_fin_ult1':'junior_acc',\n",
    "    'ind_ctma_fin_ult1':'mass_particular_acc', \n",
    "    'ind_ctop_fin_ult1':'particular_acc',\n",
    "    'ind_ctpp_fin_ult1':'particular_plus_acc', \n",
    "    'ind_deco_fin_ult1':'short_term_deposit', \n",
    "    'ind_deme_fin_ult1':'medium_term_deposits', \n",
    "    'ind_dela_fin_ult1':'long_term_deposits',\n",
    "    'ind_ecue_fin_ult1':'e_account', \n",
    "    'ind_fond_fin_ult1':'funds', \n",
    "    'ind_hip_fin_ult1':'mortgage', \n",
    "    'ind_plan_fin_ult1':'pensions1', \n",
    "    'ind_pres_fin_ult1':'loans', \n",
    "    'ind_reca_fin_ult1':'taxes', \n",
    "    'ind_tjcr_fin_ult1':'credit_card', \n",
    "    'ind_valo_fin_ult1':'securities', \n",
    "    'ind_viv_fin_ult1':'home_account',\n",
    "    'ind_cco_fin_ult1':'current_acc', \n",
    "    'ind_nomina_ult1':'payroll', \n",
    "    'ind_nom_pens_ult1':'pensions2', \n",
    "    'ind_recibo_ult1':'direct_debit'\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping first two columns as they do not give much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_code</th>\n",
       "      <th>emp_index</th>\n",
       "      <th>cust_residence</th>\n",
       "      <th>cust_gender</th>\n",
       "      <th>age</th>\n",
       "      <th>first_holder_date</th>\n",
       "      <th>new_cust_index</th>\n",
       "      <th>cust_seniority</th>\n",
       "      <th>indrel</th>\n",
       "      <th>last_date_primary_cust</th>\n",
       "      <th>...</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>pensions1</th>\n",
       "      <th>loans</th>\n",
       "      <th>taxes</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>securities</th>\n",
       "      <th>home_account</th>\n",
       "      <th>payroll</th>\n",
       "      <th>pensions2</th>\n",
       "      <th>direct_debit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1375586</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>35</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1050611</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1050612</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1050613</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1050614</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_code emp_index cust_residence cust_gender  age first_holder_date  \\\n",
       "0    1375586         N             ES           H   35        2015-01-12   \n",
       "1    1050611         N             ES           V   23        2012-08-10   \n",
       "2    1050612         N             ES           V   23        2012-08-10   \n",
       "3    1050613         N             ES           H   22        2012-08-10   \n",
       "4    1050614         N             ES           V   23        2012-08-10   \n",
       "\n",
       "   new_cust_index cust_seniority  indrel last_date_primary_cust  ...  \\\n",
       "0             0.0              6     1.0                    NaN  ...   \n",
       "1             0.0             35     1.0                    NaN  ...   \n",
       "2             0.0             35     1.0                    NaN  ...   \n",
       "3             0.0             35     1.0                    NaN  ...   \n",
       "4             0.0             35     1.0                    NaN  ...   \n",
       "\n",
       "   mortgage pensions1 loans taxes credit_card securities home_account  \\\n",
       "0         0         0     0     0           0          0            0   \n",
       "1         0         0     0     0           0          0            0   \n",
       "2         0         0     0     0           0          0            0   \n",
       "3         0         0     0     0           0          0            0   \n",
       "4         0         0     0     0           0          0            0   \n",
       "\n",
       "   payroll  pensions2 direct_debit  \n",
       "0      0.0        0.0            0  \n",
       "1      0.0        0.0            0  \n",
       "2      0.0        0.0            0  \n",
       "3      0.0        0.0            0  \n",
       "4      0.0        0.0            0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:,2:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for duplicate observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cust_code` contains customer codes. Lets check if there are duplicate customer codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281941     2\n",
       "362212     2\n",
       "362218     2\n",
       "362219     2\n",
       "362220     2\n",
       "          ..\n",
       "1310578    1\n",
       "1310579    1\n",
       "1310645    1\n",
       "1310643    1\n",
       "1183305    1\n",
       "Name: cust_code, Length: 626159, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cust_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are duplicate customer codes. Since the bank wants to segment unique customers, I will drop observations with duplicate customer codes and keep only the last observation for each duplicated customer code observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(626159, 46)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset = ['cust_code'], keep = \"last\").reset_index(drop = True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373841"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000000 - 626159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximately 370K+ duplicated observation has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626159"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cust_code'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all customer codes are unique. I will drop this variable has customer code does not give any information for customer segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_index</th>\n",
       "      <th>cust_residence</th>\n",
       "      <th>cust_gender</th>\n",
       "      <th>age</th>\n",
       "      <th>first_holder_date</th>\n",
       "      <th>new_cust_index</th>\n",
       "      <th>cust_seniority</th>\n",
       "      <th>indrel</th>\n",
       "      <th>last_date_primary_cust</th>\n",
       "      <th>cust_type</th>\n",
       "      <th>...</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>pensions1</th>\n",
       "      <th>loans</th>\n",
       "      <th>taxes</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>securities</th>\n",
       "      <th>home_account</th>\n",
       "      <th>payroll</th>\n",
       "      <th>pensions2</th>\n",
       "      <th>direct_debit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>35</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  emp_index cust_residence cust_gender  age first_holder_date  new_cust_index  \\\n",
       "0         N             ES           H   35        2015-01-12             0.0   \n",
       "1         N             ES           V   23        2012-08-10             0.0   \n",
       "2         N             ES           V   23        2012-08-10             0.0   \n",
       "3         N             ES           H   22        2012-08-10             0.0   \n",
       "4         N             ES           V   23        2012-08-10             0.0   \n",
       "\n",
       "  cust_seniority  indrel last_date_primary_cust  cust_type  ... mortgage  \\\n",
       "0              6     1.0                    NaN        1.0  ...        0   \n",
       "1             35     1.0                    NaN        1.0  ...        0   \n",
       "2             35     1.0                    NaN        1.0  ...        0   \n",
       "3             35     1.0                    NaN        1.0  ...        0   \n",
       "4             35     1.0                    NaN        1.0  ...        0   \n",
       "\n",
       "  pensions1 loans taxes credit_card securities  home_account  payroll  \\\n",
       "0         0     0     0           0          0             0      0.0   \n",
       "1         0     0     0           0          0             0      0.0   \n",
       "2         0     0     0           0          0             0      0.0   \n",
       "3         0     0     0           0          0             0      0.0   \n",
       "4         0     0     0           0          0             0      0.0   \n",
       "\n",
       "  pensions2  direct_debit  \n",
       "0       0.0             0  \n",
       "1       0.0             0  \n",
       "2       0.0             0  \n",
       "3       0.0             0  \n",
       "4       0.0             0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('cust_code', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_index                  1.115531\n",
       "cust_residence             1.115531\n",
       "cust_gender                1.115851\n",
       "age                        0.000000\n",
       "first_holder_date          1.115531\n",
       "new_cust_index             1.115531\n",
       "cust_seniority             0.000000\n",
       "indrel                     1.115531\n",
       "last_date_primary_cust    99.876549\n",
       "cust_type                  1.115531\n",
       "cust_rel_time              1.115531\n",
       "cust_res_index             1.115531\n",
       "is_foreign                 1.115531\n",
       "cust_spouse_index         99.985786\n",
       "channel_to_join            1.123676\n",
       "deceased_index             1.115531\n",
       "addres_type                1.115531\n",
       "cod_prov                   1.703561\n",
       "name_province              1.703561\n",
       "activity_index             1.115531\n",
       "household_income          17.841475\n",
       "saving_acc                 0.000000\n",
       "guarantees                 0.000000\n",
       "current_acc                0.000000\n",
       "derivada_acc               0.000000\n",
       "payroll_acc                0.000000\n",
       "junior_acc                 0.000000\n",
       "mass_particular_acc        0.000000\n",
       "particular_acc             0.000000\n",
       "particular_plus_acc        0.000000\n",
       "short_term_deposit         0.000000\n",
       "medium_term_deposits       0.000000\n",
       "long_term_deposits         0.000000\n",
       "e_account                  0.000000\n",
       "funds                      0.000000\n",
       "mortgage                   0.000000\n",
       "pensions1                  0.000000\n",
       "loans                      0.000000\n",
       "taxes                      0.000000\n",
       "credit_card                0.000000\n",
       "securities                 0.000000\n",
       "home_account               0.000000\n",
       "payroll                    0.574934\n",
       "pensions2                  0.574934\n",
       "direct_debit               0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking percentage of missing values for every variable.\n",
    "df.isna().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting variables having percentage of missing values higher than 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns to drop: Index(['last_date_primary_cust', 'cust_spouse_index'], dtype='object')\n",
      "\n",
      "(626159, 43)\n"
     ]
    }
   ],
   "source": [
    "missing_info = (df.isna().sum()/len(df)*100)\n",
    "\n",
    "to_drop = missing_info[missing_info.values > 20].index #setting threshold\n",
    "\n",
    "print(f\"columns to drop: {to_drop}\")\n",
    "print()\n",
    "\n",
    "df = df.drop(to_drop, axis = 1).reset_index(drop = True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking unique values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_index : ['N' nan 'A' 'B' 'F' 'S']\n",
      "\n",
      "cust_residence : ['ES' nan 'CA' 'CH' 'CL' 'IE' 'AT' 'NL' 'FR' 'GB' 'DE' 'DO' 'BE' 'AR' 'VE'\n",
      " 'US' 'MX' 'BR' 'IT' 'EC' 'PE' 'CO' 'HN' 'FI' 'SE' 'AL' 'PT' 'MZ' 'CN'\n",
      " 'TW' 'PL' 'IN' 'CR' 'NI' 'HK' 'AE' 'MA' 'GR' 'PR' 'RO' 'IL' 'RU' 'GT'\n",
      " 'GA' 'NO' 'SN' 'MR' 'UA' 'BG' 'PY' 'EE' 'SV' 'CZ' 'ET' 'CM' 'SA' 'CI'\n",
      " 'QA' 'SG' 'BO' 'BZ' 'UY' 'MD' 'BA' 'CF' 'KR' 'LU' 'NG' 'CD' 'ZA' 'AU'\n",
      " 'KZ' 'CU' 'DK' 'JP' 'SK' 'GM' 'AO' 'HR' 'PK' 'PA' 'MK' 'LY' 'LT' 'TH'\n",
      " 'GQ' 'GN' 'TR' 'IS' 'KE' 'VN' 'RS' 'AD' 'NZ' 'OM' 'EG' 'LV' 'ML' 'CG'\n",
      " 'GW' 'HU' 'DZ' 'SL' 'GI' 'KH' 'MM' 'BY' 'PH' 'KW' 'GH' 'TN' 'TG' 'LB'\n",
      " 'GE']\n",
      "\n",
      "cust_gender : ['H' 'V' nan]\n",
      "\n",
      "age : [' 35' ' 23' ' 22' ' 24' ' 65' ' 28' ' 25' ' 26' ' 53' ' 27' ' 32' ' 37'\n",
      " ' 31' ' 39' ' 63' ' 33' ' 55' ' 42' ' 58' ' 38' ' 50' ' 30' ' 45' ' 44'\n",
      " ' 36' ' 29' ' 60' ' 57' ' 67' ' 47' ' NA' ' 34' ' 48' ' 46' ' 54' ' 84'\n",
      " ' 15' ' 12' '  8' '  6' ' 83' ' 40' ' 77' ' 69' ' 52' ' 59' ' 43' ' 10'\n",
      " '  9' ' 49' ' 41' ' 51' ' 78' ' 16' ' 11' ' 73' ' 62' ' 66' ' 17' ' 68'\n",
      " ' 82' ' 95' ' 96' ' 56' ' 61' ' 79' ' 72' ' 14' ' 19' ' 13' ' 86' ' 64'\n",
      " ' 20' ' 89' ' 71' '  7' ' 70' ' 74' ' 21' ' 18' ' 75' '  4' ' 80' ' 81'\n",
      " '  5' ' 76' ' 92' ' 93' ' 85' ' 91' ' 87' ' 90' ' 94' ' 99' ' 98' ' 88'\n",
      " ' 97' '100' '101' '106' '103' '  3' '  2' '102' '104' '111' '112' '105'\n",
      " '107' '110' '113' '108' '109' '115' '116']\n",
      "\n",
      "first_holder_date : ['2015-01-12' '2012-08-10' nan ... '2013-12-06' '2013-08-04' '2013-09-21']\n",
      "\n",
      "new_cust_index : [ 0. nan  1.]\n",
      "\n",
      "cust_seniority : ['      6' '     35' '     34' '     NA' '     33' '     31' '     21'\n",
      " '     16' '     27' '      9' '     22' '     13' '     29' '      8'\n",
      " '     11' '     10' '     28' '     24' '      7' '     25' '     14'\n",
      " '     26' '     12' '     23' '      1' '     18' '      4' '      3'\n",
      " '     17' '     32' '     30' '     20' '     15' '     19' '    157'\n",
      " '     36' '      5' '     40' '     38' '     37' '     39' '      0'\n",
      " '      2' '     47' '     44' '     42' '     46' '     45' '     43'\n",
      " '     41' '     57' '     48' '     52' '     49' '     50' '     56'\n",
      " '     58' '     51' '     55' '     54' '     53' '     59' '     62'\n",
      " '     63' '     60' '     61' '    165' '    164' '    166' '    167'\n",
      " '    115' '    163' '    111' '     81' '     64' '    162' '    148'\n",
      " '    172' '    174' '    147' '    173' '    169' '    168' '    153'\n",
      " '    171' '    170' '    154' '    152' '    155' '    156' '    109'\n",
      " '    149' '    151' '    150' '    142' '    137' '    161' '    160'\n",
      " '    143' '    158' '    112' '    145' '    159' '    184' '     88'\n",
      " '    209' '    186' '    210' '    208' '    207' '    213' '    214'\n",
      " '    212' '    201' '    202' '    199' '    206' '    205' '    204'\n",
      " '    233' '    235' '    230' '    107' '    231' '    241' '    133'\n",
      " '    243' '    237' '    236' '    217' '    219' '    220' '    215'\n",
      " '    221' '    216' '    116' '    218' '    225' '    227' '    222'\n",
      " '    223' '    138' '    180' '    135' '    182' '    181' '    178'\n",
      " '    110' '    179' '    136' '    197' '    183' '    176' '    177'\n",
      " '    175' '    194' '    195' '    193' '    192' '    198' '    196'\n",
      " '    119' '    189' '    187' '    185' '    190' '    191' '     97'\n",
      " '     96' '    100' '    101' '     98' '     85' '     99' '     92'\n",
      " '     93' '     90' '     91' '     94' '     95' '     87' '    106'\n",
      " '    108' '    102' '    103' '    105' '    104' '     77' '     74'\n",
      " '     75' '     76' '     79' '     78' '     65' '     66' '     67'\n",
      " '     71' '     68' '     69' '     86' '     84' '     72' '     70'\n",
      " '     89' '     80' '     83' '     82' '    134' '    127' '    129'\n",
      " '    128' '    130' '    132' '    131' '    146' '    139' '    141'\n",
      " '    140' '    114' '    117' '    113' '    124' '    125' '    126'\n",
      " '    118' '    123' '    120' '    121' '     73' '    122' '    188'\n",
      " '    238' '    144' '    200' '    224' '    229' '    232' '    234'\n",
      " '    211' '-999999' '    203' '    226' '    240' '    228' '    239'\n",
      " '    246' '    242' '    244' '    245']\n",
      "\n",
      "indrel : [ 1. nan 99.]\n",
      "\n",
      "cust_type : [ 1. nan  3.  2.]\n",
      "\n",
      "cust_rel_time : ['A' 'I' nan 'P']\n",
      "\n",
      "cust_res_index : ['S' nan 'N']\n",
      "\n",
      "is_foreign : ['N' 'S' nan]\n",
      "\n",
      "channel_to_join : ['KHL' 'KHE' 'KHD' 'KFA' 'KFC' 'KAT' nan 'KAZ' 'RED' 'KHC' 'KHK' 'KGN'\n",
      " 'KHM' 'KHO' 'KDH' 'KEH' 'KAD' 'KBG' 'KGC' 'KHF' 'KFK' 'KHN' 'KHA' 'KAF'\n",
      " 'KGX' 'KFD' 'KAG' 'KFG' 'KAB' 'KCC' 'KAE' 'KAH' 'KAR' 'KFJ' 'KFL' 'KAI'\n",
      " 'KFU' 'KAQ' 'KFS' 'KAA' 'KFP' 'KAJ' 'KFN' 'KGV' 'KGY' 'KFF' 'KAP' 'KFV'\n",
      " '013' 'K00' 'KAK' 'KAO' 'KFT' 'KDR' 'KCB' 'KEY' '007' 'KAC' 'KDT' 'KAY'\n",
      " 'KAS' 'KBZ' 'KAW' 'KAL' 'KCI' 'KCH' 'KBB' 'KAM' 'KBH' 'KEJ' 'KEN' 'KCJ'\n",
      " 'KAN' 'KBM' 'KBU' 'KEZ' 'KDW' 'KDM' 'KCL' 'KBS' 'KEE' 'KBO' 'KCM' 'KEL'\n",
      " 'KEO' 'KCG' 'KEM' 'KBQ' 'KCQ' 'KDE' 'KFH' 'KED' 'KDG' 'KCN' 'KFB' 'KBF'\n",
      " 'KFM' 'KFI' 'KAV' '004' 'KEK' 'KDN' 'KBJ' 'KEG' 'KCU' 'KBR' 'KCR' 'KDS'\n",
      " 'KGW' 'KCD' 'KDF' 'KBL' 'KFE' 'KFR' 'KGU' 'KDI' 'KAU' 'KEQ' 'KCF' 'KDO'\n",
      " 'KES' 'KDC' 'KBV' 'KBW' 'KCA' 'KEW' 'KDP' 'KDQ' 'KEB' 'KDY' 'KDV' 'KEV'\n",
      " 'KEI' 'KEU' 'KDU' 'KCO' 'KCK' 'KEA' 'KBY' 'KCE' 'KCP' 'KEF' 'KDD' 'KDX'\n",
      " 'KBE' 'KBN' 'KCX' 'KDA' 'KBP' 'KCV' 'KBD' 'KCT' 'KBX' 'KDZ' 'KDB' 'KCS'\n",
      " 'KEC']\n",
      "\n",
      "deceased_index : ['N' nan 'S']\n",
      "\n",
      "addres_type : [ 1. nan]\n",
      "\n",
      "cod_prov : [29. 13. 50. 45. 24. 20. 10. 17. 49.  8. 37.  9. 22. 31.  5. 40. 27. 25.\n",
      " 28.  3. 42. 41. 39.  7. 47. 36. 46. 44. 15. 32. 23. 16. 48. 12. 26.  2.\n",
      "  6. 30. 11. nan  4. 19. 34. 35. 14. 21. 18. 33. 38. 52. 43.  1. 51.]\n",
      "\n",
      "name_province : ['MALAGA' 'CIUDAD REAL' 'ZARAGOZA' 'TOLEDO' 'LEON' 'GIPUZKOA' 'CACERES'\n",
      " 'GIRONA' 'ZAMORA' 'BARCELONA' 'SALAMANCA' 'BURGOS' 'HUESCA' 'NAVARRA'\n",
      " 'AVILA' 'SEGOVIA' 'LUGO' 'LERIDA' 'MADRID' 'ALICANTE' 'SORIA' 'SEVILLA'\n",
      " 'CANTABRIA' 'BALEARS, ILLES' 'VALLADOLID' 'PONTEVEDRA' 'VALENCIA'\n",
      " 'TERUEL' 'CORUÑA, A' 'OURENSE' 'JAEN' 'CUENCA' 'BIZKAIA' 'CASTELLON'\n",
      " 'RIOJA, LA' 'ALBACETE' 'BADAJOZ' 'MURCIA' 'CADIZ' nan 'ALMERIA'\n",
      " 'GUADALAJARA' 'PALENCIA' 'PALMAS, LAS' 'CORDOBA' 'HUELVA' 'GRANADA'\n",
      " 'ASTURIAS' 'SANTA CRUZ DE TENERIFE' 'MELILLA' 'TARRAGONA' 'ALAVA' 'CEUTA']\n",
      "\n",
      "activity_index : [ 1.  0. nan]\n",
      "\n",
      "household_income : [ 87218.1   35548.74 122179.11 ... 103533.03  80634.87  57818.46]\n",
      "\n",
      "saving_acc : [0 1]\n",
      "\n",
      "guarantees : [0 1]\n",
      "\n",
      "current_acc : [1 0]\n",
      "\n",
      "derivada_acc : [0 1]\n",
      "\n",
      "payroll_acc : [0 1]\n",
      "\n",
      "junior_acc : [0 1]\n",
      "\n",
      "mass_particular_acc : [0 1]\n",
      "\n",
      "particular_acc : [0 1]\n",
      "\n",
      "particular_plus_acc : [0 1]\n",
      "\n",
      "short_term_deposit : [0 1]\n",
      "\n",
      "medium_term_deposits : [0 1]\n",
      "\n",
      "long_term_deposits : [0 1]\n",
      "\n",
      "e_account : [0 1]\n",
      "\n",
      "funds : [0 1]\n",
      "\n",
      "mortgage : [0 1]\n",
      "\n",
      "pensions1 : [0 1]\n",
      "\n",
      "loans : [0 1]\n",
      "\n",
      "taxes : [0 1]\n",
      "\n",
      "credit_card : [0 1]\n",
      "\n",
      "securities : [0 1]\n",
      "\n",
      "home_account : [0 1]\n",
      "\n",
      "payroll : [ 0.  1. nan]\n",
      "\n",
      "pensions2 : [ 0.  1. nan]\n",
      "\n",
      "direct_debit : [0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col, \":\", df[col].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets analyze each variable. First I will begin with `emp_index` and filter those observations with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `emp_index`: Employee index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_index</th>\n",
       "      <th>cust_residence</th>\n",
       "      <th>cust_gender</th>\n",
       "      <th>age</th>\n",
       "      <th>first_holder_date</th>\n",
       "      <th>new_cust_index</th>\n",
       "      <th>cust_seniority</th>\n",
       "      <th>indrel</th>\n",
       "      <th>cust_type</th>\n",
       "      <th>cust_rel_time</th>\n",
       "      <th>...</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>pensions1</th>\n",
       "      <th>loans</th>\n",
       "      <th>taxes</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>securities</th>\n",
       "      <th>home_account</th>\n",
       "      <th>payroll</th>\n",
       "      <th>pensions2</th>\n",
       "      <th>direct_debit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624939</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625270</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625736</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625883</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6985 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emp_index cust_residence cust_gender  age first_holder_date  \\\n",
       "261          NaN            NaN         NaN   NA               NaN   \n",
       "1029         NaN            NaN         NaN   NA               NaN   \n",
       "1063         NaN            NaN         NaN   NA               NaN   \n",
       "1154         NaN            NaN         NaN   NA               NaN   \n",
       "1779         NaN            NaN         NaN   NA               NaN   \n",
       "...          ...            ...         ...  ...               ...   \n",
       "624939       NaN            NaN         NaN   NA               NaN   \n",
       "625270       NaN            NaN         NaN   NA               NaN   \n",
       "625274       NaN            NaN         NaN   NA               NaN   \n",
       "625736       NaN            NaN         NaN   NA               NaN   \n",
       "625883       NaN            NaN         NaN   NA               NaN   \n",
       "\n",
       "        new_cust_index cust_seniority  indrel  cust_type cust_rel_time  ...  \\\n",
       "261                NaN             NA     NaN        NaN           NaN  ...   \n",
       "1029               NaN             NA     NaN        NaN           NaN  ...   \n",
       "1063               NaN             NA     NaN        NaN           NaN  ...   \n",
       "1154               NaN             NA     NaN        NaN           NaN  ...   \n",
       "1779               NaN             NA     NaN        NaN           NaN  ...   \n",
       "...                ...            ...     ...        ...           ...  ...   \n",
       "624939             NaN             NA     NaN        NaN           NaN  ...   \n",
       "625270             NaN             NA     NaN        NaN           NaN  ...   \n",
       "625274             NaN             NA     NaN        NaN           NaN  ...   \n",
       "625736             NaN             NA     NaN        NaN           NaN  ...   \n",
       "625883             NaN             NA     NaN        NaN           NaN  ...   \n",
       "\n",
       "       mortgage pensions1 loans taxes  credit_card  securities home_account  \\\n",
       "261           0         0     0     0            0           0            0   \n",
       "1029          0         0     0     0            0           0            0   \n",
       "1063          0         0     0     0            0           0            0   \n",
       "1154          0         0     0     0            0           0            0   \n",
       "1779          0         0     0     0            0           0            0   \n",
       "...         ...       ...   ...   ...          ...         ...          ...   \n",
       "624939        0         0     0     0            0           0            0   \n",
       "625270        0         0     0     0            0           0            0   \n",
       "625274        0         0     0     0            0           0            0   \n",
       "625736        0         0     0     0            0           0            0   \n",
       "625883        0         0     0     0            0           0            0   \n",
       "\n",
       "        payroll  pensions2  direct_debit  \n",
       "261         0.0        0.0             0  \n",
       "1029        0.0        0.0             0  \n",
       "1063        0.0        0.0             0  \n",
       "1154        0.0        0.0             0  \n",
       "1779        0.0        0.0             0  \n",
       "...         ...        ...           ...  \n",
       "624939      0.0        0.0             0  \n",
       "625270      NaN        NaN             0  \n",
       "625274      0.0        0.0             0  \n",
       "625736      NaN        NaN             0  \n",
       "625883      0.0        0.0             0  \n",
       "\n",
       "[6985 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['emp_index'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_index               6985\n",
       "cust_residence          6985\n",
       "cust_gender             6985\n",
       "age                        0\n",
       "first_holder_date       6985\n",
       "new_cust_index          6985\n",
       "cust_seniority             0\n",
       "indrel                  6985\n",
       "cust_type               6985\n",
       "cust_rel_time           6985\n",
       "cust_res_index          6985\n",
       "is_foreign              6985\n",
       "channel_to_join         6985\n",
       "deceased_index          6985\n",
       "addres_type             6985\n",
       "cod_prov                6985\n",
       "name_province           6985\n",
       "activity_index          6985\n",
       "household_income        6985\n",
       "saving_acc                 0\n",
       "guarantees                 0\n",
       "current_acc                0\n",
       "derivada_acc               0\n",
       "payroll_acc                0\n",
       "junior_acc                 0\n",
       "mass_particular_acc        0\n",
       "particular_acc             0\n",
       "particular_plus_acc        0\n",
       "short_term_deposit         0\n",
       "medium_term_deposits       0\n",
       "long_term_deposits         0\n",
       "e_account                  0\n",
       "funds                      0\n",
       "mortgage                   0\n",
       "pensions1                  0\n",
       "loans                      0\n",
       "taxes                      0\n",
       "credit_card                0\n",
       "securities                 0\n",
       "home_account               0\n",
       "payroll                 3527\n",
       "pensions2               3527\n",
       "direct_debit               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['emp_index'].isna()].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 6985 observation having missing values across multiple columns. It would be impossible to impute these observations with meaning full information as other columns belonging to same observation has missing values too. Therefore, I will drop these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619174, 43)\n"
     ]
    }
   ],
   "source": [
    "to_drop = df[df['emp_index'].isna()].index\n",
    "\n",
    "df = df.drop(index = to_drop, axis = 0).reset_index(drop = True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['emp_index']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['emp_index'].value_counts())\n",
    "print()\n",
    "print(df['emp_index'].value_counts(normalize = True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employee index: \n",
    "* A: active, \n",
    "* B: ex employed, \n",
    "* F: filial, \n",
    "* N: not employee, \n",
    "* P: pasive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all customers are active. Only a small negligible portion of customers belong to other categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cust_residence`: Customer's Country residence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(df['cust_residence'].isna()) # No Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['cust_residence'].value_counts())\n",
    "print()\n",
    "df['cust_residence'].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99.4% of customers are from spain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `'cust_gender`: Customer's Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cust_gender'].isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing `'cust_gender` variable with the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cust_gender'] = df['cust_gender'].fillna(df['cust_gender'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['cust_gender']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'V' category is higher in proportion compared to 'H'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `age`: Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variable is supposed to be numerical, but currently it is of object data type. In order to convert this variable to numerical, the 'NA' value must be dealt with first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('age == \" NA\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, when dealing with missing values in `emp_index`, the NA values in `age` has also been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting age to numerical\n",
    "df['age'] = df['age'].str.strip().astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (13,5));\n",
    "\n",
    "sns.histplot(df['age'], kde = True, ax = ax[0]);\n",
    "sns.boxplot(x = 'age', data = df, ax = ax[1]);\n",
    "\n",
    "plt.suptitle(\"Age Distribution of Customers\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age distribution is Bi-modal, where majority of customers are young, between the age of 20-30, followed by older customers, between the age of 40 and 50. There seems to outliers in both sides of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are customers as young as 2 years and customers as old as 116 years!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will assign ages below 18 as 18. For ages older than 85, I will assign 85.\n",
    "\n",
    "This method will take care of outliers on both sides of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ages where below 18 will be assigned as 24, and ages above 85 will be assigned as 45.\n",
    "# df['age'] = np.where(df['age'] < 20, 18, (np.where(df['age'] > 85, 85, df['age'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,2, figsize = (13,5));\n",
    "\n",
    "# sns.histplot(df['age'], kde = True, ax = ax[0]);\n",
    "# sns.boxplot(x = 'age', data = df, ax = ax[1]);\n",
    "\n",
    "# plt.suptitle(\"Age Distribution of Customers\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no more outliers in the age distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `first_holder_date`: the date in which the customer became as the first holder of a contract in the bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['first_holder_date'].isna())) #No missing value\n",
    "print()\n",
    "df['first_holder_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to Datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_holder_date'] = pd.to_datetime(df['first_holder_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_holder_date_year'] = df.first_holder_date.dt.year #Extracting years\n",
    "df['first_holder_date_month'] = df.first_holder_date.dt.month #extracting months\n",
    "df['first_holder_date_day'] = df.first_holder_date.dt.weekday #extracting day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.groupby('first_holder_date').size().reset_index().rename(columns = {0:\"count\"})\n",
    "\n",
    "plt.figure(figsize = (13,6));\n",
    "ax = sns.lineplot(x = 'first_holder_date', y = 'count', data = temp_df);\n",
    "ax.set_title(\"Daily Activies\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant spike in customers after 2010. There seems to be an upward trand and seasonality in number of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.groupby('first_holder_date_year').size().reset_index().rename(columns = {0:\"count\"})\n",
    "\n",
    "plt.figure(figsize = (13,6));\n",
    "ax = sns.lineplot(x = 'first_holder_date_year', y = 'count', data = temp_df);\n",
    "ax.set_xticks(np.arange(1995, 2016, 1));\n",
    "ax.set_title(\"Activities Per Year\");\n",
    "ax.set_xlabel(\"Year\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years between 2011 and 2014 saw the highest number of applicants compared to other years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.groupby('first_holder_date_month').size().reset_index().rename(columns = {0:\"count\"})\n",
    "\n",
    "plt.figure(figsize = (13,6));\n",
    "ax = sns.lineplot(x = 'first_holder_date_month', y = 'count', data = temp_df);\n",
    "plt.xticks(np.arange(1, 13, 1), [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\",\n",
    "                                 \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]);\n",
    "ax.set_title(\"Activities by Month\");\n",
    "ax.set_xlabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all years, most customers join during the month of october."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.groupby('first_holder_date_day').size().reset_index().rename(columns = {0:\"count\"})\n",
    "\n",
    "plt.figure(figsize = (13,6));\n",
    "ax = sns.lineplot(x = 'first_holder_date_day', y = 'count', data = temp_df);\n",
    "plt.xticks(np.arange(0, 7, 1), ['Mon', 'Tue', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']);\n",
    "ax.set_title(\"Activities by Week Days\");\n",
    "ax.set_xlabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monday sees the highest number of customers. Number of customers are lowest during the weekends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28th to 32nd week in a year shows an increase in number of customers (july to august) followed by an increase again during week 40 (October)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping `fetcha_alta` as all the important information has already been extracted.\n",
    "\n",
    "df = df.drop('first_holder_date', axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `new_cust_index`: New customer Index. 1 if the customer registered in the last 6 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['new_cust_index'].isna())) #No missing value\n",
    "print()\n",
    "df['new_cust_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['new_cust_index']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_cust_index'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cust_seniority`: Customer seniority (in months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['cust_seniority'].isna())) #No missing value\n",
    "print()\n",
    "df['cust_seniority']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to numerical\n",
    "\n",
    "df['cust_seniority'] = df['cust_seniority'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cust_seniority'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"cust_seniority == -999999\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are couple of observations with -999999 as value. This is clearly an error. Hence, these observations will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = df.query(\"cust_seniority == -999999\").index\n",
    "\n",
    "df = df.drop(index = to_drop, axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cust_seniority'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize = (12,10));\n",
    "\n",
    "sns.histplot(df['cust_seniority'], kde = True, ax = ax[0]);\n",
    "sns.boxplot(x = 'cust_seniority', data = df, ax = ax[1]);\n",
    "\n",
    "plt.suptitle(\"Customer Seniority Distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no outliers for this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `indrel`: 1 (First/Primary), 99 (Primary customer during the month but not at the end of the month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['indrel'].isna())) #No missing value\n",
    "print()\n",
    "df['indrel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['indrel'] = df['indrel'].replace(99.0, 0.0)\n",
    "df['indrel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **cust_type** : Customer type at the beginning of the month: 1 (First/Primary customer), 2 (co-owner), P (Potential), 3 (former primary), 4(former co-owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['cust_type'].isna()))\n",
    "\n",
    "df['cust_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping co-owner category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index = df.query(\"cust_type == 2.0\").index, axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cust_rel_time`: Customer relation type at the beginning of the month, A (active), I (inactive), P (former customer),R (Potential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['cust_rel_time'].isna()))\n",
    "\n",
    "df['cust_rel_time'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"P\" refers to former customers. Since the bank is only interested in current customers, I will drop observations having `tripel_1mes` has \"P\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = df.query(\"cust_rel_time == 'P'\").index\n",
    "\n",
    "df = df.drop(index = to_drop, axis = 0).reset_index(drop = True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cust_res_index`: Residence index (S (Yes) or N (No) if the residence country is the same than the bank country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['cust_res_index'].isna()))\n",
    "\n",
    "df['cust_res_index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cust_res_index'] = df['cust_res_index'].map({\"S\" : 1, \"N\" : 0})\n",
    "df['cust_res_index'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `is_foreign`: Foreigner index (S (Yes) or N (No) if the customer's birth country is different than the bank country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['is_foreign'].isna()))\n",
    "\n",
    "df['is_foreign'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_foreign'] = df['is_foreign'].map({\"S\" : 1, \"N\" : 0})\n",
    "df['is_foreign'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `channel_to_join`: channel used by the customer to join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(df['channel_to_join'].isna().sum())\n",
    "df[df['channel_to_join'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 26 observations with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('cust_residence == \"ES\"')['channel_to_join'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['channel_to_join'].isna()]['cust_rel_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('cust_rel_time == \"A\"')['channel_to_join'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the observations with missing values are from those customers from Spain. Therefore, I will impute this values with the mode of those customers from Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = df.query(\"cust_rel_time=='A' & cust_residence=='ES' & name_province=='MADRID'\")['channel_to_join'].mode()[0]\n",
    "\n",
    "df['channel_to_join'] = df['channel_to_join'].fillna(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `deceased_index`: Deceased index. N/S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['deceased_index'].isna()))\n",
    "\n",
    "df['deceased_index'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deceased_index'] = df['deceased_index'].map({\"S\" : 1, \"N\" : 0})\n",
    "df['deceased_index'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `addres_type`: Address type. 1, primary address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['addres_type'].isna()))\n",
    "\n",
    "df['addres_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is only one category for this variable, I will drop this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('addres_type', axis = 1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cod_prov` & `name_province`: Province code (customer's address) / Province name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cod_prov'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name_province'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these variables are same since one `name_province` is the name of the province and `cod_prov` is the number assigned to the province. Hence I will remove `cod_prov`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('cod_prov', axis = 1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['name_province'].isna().sum())\n",
    "df[df['name_province'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 3k missing values for this column. Most of the customers are not from Spain. Therefore, I will impute this column with the mode of the category of customers outside of Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name_province'].isna()]['cust_residence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('cust_residence != \"ES\"')['name_province'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing for thise customers from Spain.\n",
    "(df[df['name_province'].isna()]['cust_residence'] == \"ES\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Imputing for those customers outside of Spain\n",
    "for i in df[df['name_province'].isna()].index:\n",
    "    if df['cust_residence'][i] != \"ES\":\n",
    "        df['name_province'][i] = \"Foreign\"\n",
    "    else:\n",
    "        df['name_province'][i] = \"MADRID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `activity_index`: Activity index (1, active customer; 0, inactive customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(any(df['activity_index'].isna()))\n",
    "\n",
    "df['activity_index'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `household_income`: Gross income of the household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['household_income'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 100k+ missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize = (13,8), sharex = True);\n",
    "\n",
    "sns.histplot(df['household_income'], kde = True, ax = ax[0]);\n",
    "sns.boxplot(x = 'household_income', data = df, ax = ax[1]);\n",
    "\n",
    "plt.suptitle(\"Income Distribution of Customers\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['household_income'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the distribution is extremely skewed. Only fewer households earns income higher than 100k. Therefore imputing this variable with mean would not be the right approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.groupby('name_province').agg({'household_income' : 'median'}).sort_values('household_income').reset_index()\n",
    "\n",
    "plt.figure(figsize = (8, 20));\n",
    "sns.barplot(x = 'household_income', y = 'name_province', data = temp_df, palette = \"viridis\");\n",
    "plt.xlabel(\"Median Household Income\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see certain cities have higher median income compared to other cities. Therefore, I will impute this variable by filtering by province and then taking the median income of that province."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for city in df['name_province'].unique():\n",
    "    if city == \"ALAVA\":\n",
    "        df.loc[(df['name_province'] == f\"{city}\") & (df['household_income'].isna()), \"household_income\"] = \\\n",
    "        df['household_income'].median()\n",
    "    else:\n",
    "        df.loc[(df['name_province'] == f\"{city}\") & (df['household_income'].isna()), \"household_income\"] = \\\n",
    "        df.query(f'name_province == \"{city}\"')['household_income'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize = (13,8), sharex = True);\n",
    "\n",
    "sns.histplot(df['household_income'], kde = True, ax = ax[0]);\n",
    "sns.boxplot(x = 'household_income', data = df, ax = ax[1]);\n",
    "\n",
    "plt.suptitle(\"Income Distribution of Customers\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['household_income'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from above plot, the distribution is highly skewed. I will check whether applying feature scaling technique such as QuantileTransformer will help with the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "qt = QuantileTransformer(output_distribution = 'normal')\n",
    "\n",
    "scaled = qt.fit_transform(df[['household_income']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (10,6))\n",
    "\n",
    "sns.histplot(scaled, kde = True, ax = ax[0]).set_title(\"Household Income\");\n",
    "sns.boxplot(scaled, ax = ax[1]).set_title(\"Household Income\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(output_distribution = 'normal')\n",
    "\n",
    "qt_scaled = qt.fit_transform(df[['age', 'cust_seniority']])\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (13,6))\n",
    "\n",
    "sns.histplot(qt_scaled[:,0], kde = True, ax = ax[0]).set_title(\"age\");\n",
    "sns.histplot(qt_scaled[:,1], kde = True, ax = ax[1]).set_title(\"cust_seniority\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above plots that quantile transformer is good at transforming all of three variables to nearly normal distribution. Hence, for feature scaling, QuantileTransformer will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bank Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_cols = ['saving_acc', 'guarantees', 'current_acc', 'derivada_acc', \n",
    "             'payroll_acc', 'junior_acc', 'mass_particular_acc', 'particular_acc',\n",
    "             'particular_plus_acc', 'short_term_deposit', 'medium_term_deposits', 'long_term_deposits', \n",
    "             'e_account', 'funds', 'mortgage', 'pensions1', \n",
    "             'loans', 'taxes', 'credit_card', 'securities',\n",
    "             'home_account', 'payroll', 'pensions2', 'direct_debit']\n",
    "\n",
    "labels = [\n",
    "    \"Saving Account\", \"Guarantees\", \"Current Accounts\", \"Derivada Account\", \"Payroll Account\",\n",
    "    \"Junior Account\", \"Más particular Account\", \"particular Account\", \"particular Plus Account\",\n",
    "    \"Short-term deposits\", \"Medium-term deposits\", \"Long-term deposits\", \"e-account\", \n",
    "    \"Funds\", \"Mortgage\", \"Pensions\", \"Loans\", \"Taxes\", \"Credit Card\", \"Securities\", \n",
    "    \"Home Account\", \"Payroll\", \"Pensions\", \"Direct Debit\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col, name  in zip(prod_cols, labels):\n",
    "    print(col, \":\", name)\n",
    "    print(\"-\" * 50)\n",
    "    print(f'Missing Values: {df[col].isna().sum()}')\n",
    "    print(\"Value Counts\")\n",
    "    print(df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 2 columns featuring certain bank products have missing values. I will impute these with the mode again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pensions1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pensions2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_idx = df[df['pensions2'].notna()].index\n",
    "print(len(compare_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[compare_idx, 'pensions1'] == df.loc[df['pensions2'].notna(), 'pensions2']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these accounts are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payroll'] = df['payroll'].fillna(df['payroll'].mode()[0])\n",
    "df['pensions2'] = df['pensions2'].fillna(df['pensions2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All missing values has been taken care of!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = df.groupby('age').agg({col : 'sum' for col in prod_cols})\n",
    "product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.plot(kind='bar', stacked=True, fontsize=14, figsize=[16,8], colormap='rainbow', \n",
    "               edgecolor = \"black\")\n",
    "plt.title('Distribution of products among customers by age', fontsize=20, color='black') \n",
    "plt.xlabel('Products', fontsize=17, color='black') \n",
    "plt.ylabel('Age', fontsize=17, color='black') \n",
    "# plt.ticklabel_format(style = 'plain')\n",
    "plt.legend(labels = labels, prop={'size':15}, loc=1, bbox_to_anchor=(1.0, -0.1), ncol = 5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above graph referred from [here](https://medium.com/@ravitee/santander-product-recommendation-ee4122d15072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proportion of products by age of customers\n",
    "prod_prop = product_df.div(product_df.sum(axis = 1), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prod_prop.plot(kind = 'barh', stacked = True, fontsize=14, figsize=[12,35], colormap='Set1', \n",
    "               edgecolor = \"black\");\n",
    "\n",
    "plt.title('Proportion of products among customers by age', fontsize=20, color='black') ;\n",
    "plt.xlabel('Age', fontsize=17, color='black') ;\n",
    "plt.ylabel('Product Proportion', fontsize=17, color='black') ;\n",
    "plt.legend(labels = labels, prop={'size':15}, loc=1, bbox_to_anchor=(0.95, -0.07), ncol = 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer with age above 25 opt for more products from the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above clearly shows some customers hold multiple accounts. A new variable will be created that sums all the products together to see the total number of accounts a customer holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_accounts'] =  df.iloc[:, 16:-4].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_accounts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "sns.countplot(y = 'total_accounts', data = df);\n",
    "plt.title(\"Count of Number of Accounts owned by Customers\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the customers only hold a single account. But there are considerable other customers holding multiple accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are almost 13K rows with same attributes. I will create a new column that will contain the number of duplicates for rows having the same attributes, followed by dropping all duplicate observations. This column can potentially be used as weights for those observations having same attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dup_rows_count'] = df.groupby(df.columns.to_list())['emp_index'].transform(\"size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "sns.countplot(y = 'dup_rows_count', data = df.query(\"dup_rows_count > 1\"));\n",
    "plt.title(\"Count of Number of rows with same attributes\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some columns with high cardinality, having more than 100 categories. In order to reduce the number of categories, I will group them by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['cust_residence'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cust_residence'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 113 countries. I will combine some categories by continent. Only ES will be kept separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing country by continent data\n",
    "\n",
    "url = \"https://pkgstore.datahub.io/JohnSnowLabs/country-and-continent-codes-list/country-and-continent-codes-list-csv_csv/data/b7876b7f496677669644f3d1069d3121/country-and-continent-codes-list-csv_csv.csv\"\n",
    "\n",
    "country = pd.read_csv(url)\n",
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are some missing values. This is actually because pandas sees \"NA\" and \n",
    "#considers these as missing values.\n",
    "\n",
    "country[country['Two_Letter_Country_Code'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country['Two_Letter_Country_Code'] = country['Two_Letter_Country_Code'].fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country['Two_Letter_Country_Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country['Continent_Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country[country['Continent_Code'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these countries belong to the continent of North America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country['Continent_Code'] = country['Continent_Code'].fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = country[['Continent_Code', 'Two_Letter_Country_Code']]\n",
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.setdiff1d(df['cust_residence'].unique(), country['Two_Letter_Country_Code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country.loc[country['Two_Letter_Country_Code'] == 'US', 'Continent_Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in df['cust_residence'].unique():\n",
    "    if i == \"ES\":\n",
    "        pass\n",
    "    else:\n",
    "        df.loc[df['cust_residence'] == i, \"cust_residence\"] = \\\n",
    "        country.loc[country['Two_Letter_Country_Code'] == i, 'Continent_Code'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cust_residence'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming categories to avoid confusions in future\n",
    "\n",
    "df['cust_residence'] = df['cust_residence'].map({\n",
    "    'ES' : \"Spain\",\n",
    "    'NA' : \"NorthAmerica\",\n",
    "    'EU' : \"Europe\",\n",
    "    'AS' : \"Asia\",\n",
    "    'AF' : \"Africa\",\n",
    "    'SA' : \"SouthAmerica\",\n",
    "    'OC' : 'Oceania'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['cust_residence'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 103 categories, we have grouped countries (except ES) by continent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for value counts for categorical variables\n",
    "\n",
    "for col in df.select_dtypes(include = \"object\").columns:\n",
    "    print(df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the dataset is cleaned and ready for the next steps (EDA and modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving a copy\n",
    "df_preprocessed = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will create a pipeline that will encode categorical columns to numerical data types. I will later pickle this encoder to be used for the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For columns that has more than 100 categories, I will encode those variables with CountFrequency encoder where each category will be encoded with its frequency within that column. \n",
    "\n",
    "For other categorical columns having lesser categories, I will apply one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from feature_engine.encoding import OneHotEncoder, CountFrequencyEncoder\n",
    "\n",
    "col_transformer = make_pipeline(\n",
    "    (OneHotEncoder(top_categories = 4, variables = [\"emp_index\"])),\n",
    "    (OneHotEncoder(variables = [\"cust_gender\", \"cust_rel_time\", \"cust_residence\"])), \n",
    "    (CountFrequencyEncoder(encoding_method='frequency', variables=['name_province', 'channel_to_join']))\n",
    ")\n",
    "\n",
    "col_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_transformed = col_transformer.fit_transform(df)\n",
    "\n",
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (13,6))\n",
    "\n",
    "sns.histplot(df_transformed['channel_to_join'], kde = True, ax = ax[0]);\n",
    "sns.histplot(df_transformed['name_province'], kde = True, ax = ax[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "606227/1000000 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000000 - 606227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_transformed.corr()\n",
    "select_corr = corr[abs(corr) > 0.5]\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(select_corr, annot = True, center = 0, fmt = \".1g\", annot_kws={\"fontsize\":13, \n",
    "                                                                           \"color\" : \"black\"});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All missing values, duplicated values and outliers has been taken care of. From 1 million observations, almost 400K have been dropped. Through the techniques Joseph has employed, around 60% of data has been maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving preprocessed dataset and column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving latest changes to a CSV file\n",
    "# df_preprocessed.to_csv(\"df_preprocessed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(col_transformer, open('col_transformer.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
